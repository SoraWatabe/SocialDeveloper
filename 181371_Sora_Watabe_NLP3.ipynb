{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoraWatabe/SocialDeveloper/blob/master/181371_Sora_Watabe_NLP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Byte Language Model\n",
        "\n",
        "1. Copy this colab notebook into your google drive.\n",
        "2. You need background knowledge for [Python](https://www.python.org/) and [NumPy](https://numpy.org/).\n",
        "3. Run the cells yourself and tweak the code so that the byte-wise language model works as expected. Note that the current implementation does not perform any smoothing and thus leading to `inf` perplexity.\n",
        "4. Save this colab notebook as a pdf via **Print** in the file menu and submit it to https://edu-portal.naist.jp/ under **Lecture #3** of **2023 NAIST 4102 NLP** using the report submission portal. Please make sure that all the codes and the execution results are visible for the assessment.\n",
        "5. Due date is **December 22nd, 2023**.\n",
        "\n",
        "For help regarding [Colab](https://colab.research.google.com/) or any technical issues, ask our TA, Yusuke Ide <ide.yusuke.jp6@is.naist.jp>.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eaOn1Go7NCSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x3X8DSpYMnFR"
      },
      "outputs": [],
      "source": [
        "#@markdown Please fill in your name, student id and email address.\n",
        "\n",
        "name = 'Sora Watabe' #@param {type: 'string'}\n",
        "stuent_id = '181371' #@param {type: 'string'}\n",
        "email = 'watabe.sora.wm8@is.naist.jp' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "We will give 70 points for fixing a bug in the following code so that it can return perplexity values correctly, i.e., finite values, not, e.g., `Inf`. Additional points, i.e., maximum of 30, are given based on the ranking of the perpelxity, i.e., lower is better, among submissions.\n",
        "\n",
        "* We will rank by the sum of three byte-wise perplexities, not word-wise perplexities, measured on three languages, Czech, German and Chinese.\n",
        "* The scores are linearly computed among ranks. E.g., 30 is given to the submission with the lowest perplexity, 0 to those with the highest perplexity, and 15 to those in the middle of the ranks.\n",
        "* Ties are grouped together as a bin, and their scores are computed by taking the average in the bins. For example, if a bin has 3 submissions with their linearly assigned scores of 13, 14 and 15, the average, i.e., $(13 + 14 + 15) / 3 = 14$, will be credited to those three.\n",
        "* You can use any external libraries so long as you don't break APIs as documented/commented in the code.\n",
        "\n",
        "### Penalties\n",
        "\n",
        "The byte-wise perplexity will be penalyzed by adding a penaty term when the cumulative product of sum of probabilities is not closer to 1 using the following formula:\n",
        "\n",
        "$penalty = \\max(\\operatorname{abs}(1 - \\prod_{t=1}^{T} \\sum_{y=0}^{255} p(y | x_{<t})) - 0.001, 0) \\times 100$\n",
        "\n",
        "where $x_t$ is a byte in a file $\\boldsymbol{x}$ at position $t$. Note that your language model must be probabilitistic in that sum over all byte values must be equal to one given any histories.\n",
        "\n",
        "### Extras\n",
        "\n",
        "Those who tried \"unique methods\" will be given at most 10 points in addition to the base and ranking points. The uniqueness is determined whether a submission employs a smoothing method other students have not tried. However, maximum 10 points will be deducted when violating rules, e.g., changing part of the codes/APIs which should not be modified."
      ],
      "metadata": {
        "id": "p4gtwt2NWyPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download datasets\n",
        "\n",
        "We will down load the datasets to train and test your language models. The dataset is extracted from [WMT 2023 Shared Task](https://www2.statmt.org/wmt23/translation-task.html).\n"
      ],
      "metadata": {
        "id": "Xfi4Sd4kT3Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file to \"/content\" directory.\n",
        "!gdown 1D4ZUslrY_TLRi_DSW7DtGFHm7Fl4YNrJ\n",
        "\n",
        "# Unzip it.\n",
        "!unzip -o byte-language-model-2023.zip\n",
        "\n",
        "# Create smaller training datasets comprising 10000 sentences for development\n",
        "# purposes.\n",
        "! head -10000 byte-language-model-2023/news-commentary-v18.cs.txt > news-commentary-v18-small.cs.txt\n",
        "! head -10000 byte-language-model-2023/news-commentary-v18.de.txt > news-commentary-v18-small.de.txt\n",
        "! head -10000 byte-language-model-2023/news-commentary-v18.zh.txt > news-commentary-v18-small.zh.txt"
      ],
      "metadata": {
        "id": "khLcyFcco2H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d0cc94-4e48-4a64-f3a1-86b128b0a00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D4ZUslrY_TLRi_DSW7DtGFHm7Fl4YNrJ\n",
            "To: /content/byte-language-model-2023.zip\n",
            "100% 68.7M/68.7M [00:02<00:00, 28.9MB/s]\n",
            "Archive:  byte-language-model-2023.zip\n",
            "  inflating: byte-language-model-2023/news-commentary-v18.cs.txt  \n",
            "  inflating: byte-language-model-2023/news-commentary-v18.de.txt  \n",
            "  inflating: byte-language-model-2023/news-commentary-v18.zh.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2022.cs.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2022.de.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2022.zh.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2023.cs.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2023.de.txt  \n",
            "  inflating: byte-language-model-2023/wmttest2023.zh.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verifies the extracted files\n",
        "\n",
        "We will compute the md5 checksums to make sure that you are using the correct files. You will observe the following outputs:\n",
        "\n",
        "```bash\n",
        "27f491a6c461d2476cc1a2636ca335a5  byte-language-model-2023/news-commentary-v18.cs.txt\n",
        "c5cf2b0f973eccb12e45a56039d44f99  byte-language-model-2023/news-commentary-v18.de.txt\n",
        "73393083e83b20fa09d94730ae336ddd  byte-language-model-2023/news-commentary-v18.zh.txt\n",
        "49fac4990f87cbac47cd0811e0b37f34  byte-language-model-2023/wmttest2022.cs.txt\n",
        "4fb8d232846ed6f66662163ff1e319e3  byte-language-model-2023/wmttest2022.de.txt\n",
        "4da911905616d01cce3a06b5354b4146  byte-language-model-2023/wmttest2022.zh.txt\n",
        "dea2aeda559fe2c6237a95a57c48b589  byte-language-model-2023/wmttest2023.cs.txt\n",
        "e9ef45facac4b236d22b2525bf6e3391  byte-language-model-2023/wmttest2023.de.txt\n",
        "d544edaac936c509f958a3f1309124dd  byte-language-model-2023/wmttest2023.zh.txt\n",
        "```\n",
        "\n",
        "Note that we will use `news-commentary-v18.{cs,de,zh}.txt` for training and `wmttest2023.{cs,de,zh}.txt` for the final testing. `wmttest2022.{cs,de,zh}.txt` will be used for your development purposes, e.g., debugging or fine tuning hyperparameters."
      ],
      "metadata": {
        "id": "L9pYXO_ucNjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs md5sum for the unzipped file.\n",
        "# please make sure tat the hash codes are the same.\n",
        "\n",
        "!md5sum byte-language-model-2023/*"
      ],
      "metadata": {
        "id": "fcoWlZ33cNF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a148870-5e2d-4bcb-f523-a6567927e9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27f491a6c461d2476cc1a2636ca335a5  byte-language-model-2023/news-commentary-v18.cs.txt\n",
            "c5cf2b0f973eccb12e45a56039d44f99  byte-language-model-2023/news-commentary-v18.de.txt\n",
            "73393083e83b20fa09d94730ae336ddd  byte-language-model-2023/news-commentary-v18.zh.txt\n",
            "49fac4990f87cbac47cd0811e0b37f34  byte-language-model-2023/wmttest2022.cs.txt\n",
            "4fb8d232846ed6f66662163ff1e319e3  byte-language-model-2023/wmttest2022.de.txt\n",
            "4da911905616d01cce3a06b5354b4146  byte-language-model-2023/wmttest2022.zh.txt\n",
            "dea2aeda559fe2c6237a95a57c48b589  byte-language-model-2023/wmttest2023.cs.txt\n",
            "e9ef45facac4b236d22b2525bf6e3391  byte-language-model-2023/wmttest2023.de.txt\n",
            "d544edaac936c509f958a3f1309124dd  byte-language-model-2023/wmttest2023.zh.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries\n",
        "\n",
        "Adds necessary imports here if you want to use additional libraries."
      ],
      "metadata": {
        "id": "mbM4x0Ht4JtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries used in this colab.\n",
        "import collections\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EwlCwsiGsFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language model implementation\n",
        "\n",
        "`ByteLM` is a language model class which loads a training data, estimate parameters and test it on a file to compute byet-wise perplexity."
      ],
      "metadata": {
        "id": "8wt8sYGWUIqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ByteLM:\n",
        "  \"\"\"Byte language model.\n",
        "\n",
        "  This is a very naive language model, in which byte-wise ngram probabilities\n",
        "  are estimated by maximum-likelihood without considering an issue of\n",
        "  out-of-vocabulary.\n",
        "\n",
        "  You may want to tweak `__init__`, `initial_state` and `logprob` methods to\n",
        "  alleviate the problem. Howeveer, do not change `perplexity` for a fair\n",
        "  comparison with other models implemented by other students. When changing part\n",
        "  of the codes, please try to make it readable by using appropriate variable\n",
        "  names or adding comments. Feel free to add additional methods, if necessary.\n",
        "\n",
        "  Usages:\n",
        "    ```python\n",
        "    lm = ByteLM(path/to/train/data)\n",
        "    perplexity, prob = lm.perplexity(path/to/test/data)\n",
        "    ```\n",
        "  \"\"\"\n",
        "\n",
        "  # DO NOT CHANGE BOS VALUE.\n",
        "  # 0 will never appear in a text, thus, used it as a special symbol for\n",
        "  # a beginning-of-sentence symbol, i.e., BOS.\n",
        "  BOS: int = 0\n",
        "\n",
        "  def __init__(self, filename: str, order: int=3) -> None:\n",
        "    \"\"\"Initializes `ByteLM`.\n",
        "\n",
        "    You can change the arguments for this method if necessary, e.g., adding\n",
        "    hyperparameters to this model.\n",
        "\n",
        "    Args:\n",
        "      filename: str, text file to train this language model.\n",
        "      order: int, the n-gram order that should be greater than 1.\n",
        "    \"\"\"\n",
        "    if order <= 1:\n",
        "      raise ValueError(f'`order` must be greater than 1: {order}')\n",
        "    self.order = order\n",
        "\n",
        "    # You can try revise the code in this method to fix a bug and to achieve\n",
        "    # lower perplexity.\n",
        "\n",
        "    # Collect n-gram counts.\n",
        "    ngram_counts = collections.defaultdict(lambda: np.zeros([256]))\n",
        "    with open(filename, 'br') as f:\n",
        "      for line in f:  # read as a byte string.\n",
        "        buffer = [self.BOS] + list(line)  # `buffer` is now a list of integers.\n",
        "        for n in range(1, self.order + 1):\n",
        "          for i in range(len(buffer) - n + 1):\n",
        "            ngram = buffer[i:i + n]\n",
        "            ngram_counts[tuple(ngram[:-1])][ngram[-1]] += 1\n",
        "\n",
        "    # Maximum likelihood estimate for language model.\n",
        "    self.ngrams: Dict[Tuple[int], np.ndarray] = {}\n",
        "    for context, counts in ngram_counts.items():\n",
        "      # Maximum likelihood estimate w/o smoothing.\n",
        "      probs = counts / np.sum(counts)\n",
        "      # Computes log probabilities, but assigns -inf for zero probabilities.\n",
        "      log_probs = np.where(probs == 0.0, -np.inf, np.log(probs))\n",
        "      self.ngrams[context] = log_probs\n",
        "\n",
        "  def initial_state(self) -> Any:\n",
        "    \"\"\"Returns an initial state for language model computation.\n",
        "\n",
        "    You can change the code in this method, but keep the API, e.g, input\n",
        "    arguments, so that `perplexity()` method works as expected.\n",
        "\n",
        "    Returns:\n",
        "      A state representation for log probabilities computation.\n",
        "    \"\"\"\n",
        "    # You can revise the code here for lower perplexity.\n",
        "    return []\n",
        "\n",
        "  def logprob(self, state: Any, x: int) -> Tuple[np.ndarray, Any]:\n",
        "    \"\"\"Returns log probabilities for the current input byte.\n",
        "\n",
        "    You can change the code in this method, but keep the API, e.g, input\n",
        "    arguments, so that `perplexity()` method works as expected.\n",
        "\n",
        "    Args:\n",
        "      state: A state to compute log probability.\n",
        "      x: int, the current byte to compute `p(y | state, x)`.\n",
        "    Returns:\n",
        "      A pair of (log_probs, next_state) where `log_probs` is `np.ndarray` of log\n",
        "      probabilities p(y | state, x) of all bytes y, and `next_state` is a new\n",
        "      state for the next log probability computation with a new input. Note that\n",
        "      `log_probs[y]` is equal to `log p(y | state, x)`,\n",
        "      `log_probs.shape == (256,)`, `np.exp(log_probs) >= 0` and\n",
        "      `np.sum(np.exp(log_probs)) == 1`.\n",
        "    \"\"\"\n",
        "    # You many want to revise the code in this method to achieve lower\n",
        "    # perplexity.\n",
        "\n",
        "    # Backoff to lower order when necessary.\n",
        "    state = (state + [x])[-self.order + 1:]\n",
        "    for i in range(len(state), 0, -1):\n",
        "       context = state[-i:]\n",
        "       assert len(context) < self.order\n",
        "       ret = self.ngrams.get(tuple(context), None)\n",
        "       if ret is not None:\n",
        "         return ret, context\n",
        "\n",
        "    # Backoff to unigram.\n",
        "    ret = self.ngrams.get((), None)\n",
        "    assert ret is not None\n",
        "    return ret, []\n",
        "\n",
        "  def perplexity(self, filename: str) -> Tuple[float, float]:\n",
        "    \"\"\"Computes perplexity for text data.\n",
        "\n",
        "    DO NOT CHANGE THE API OR CODE IN THIS METHOD.\n",
        "\n",
        "    Args:\n",
        "      filename: str, text file to compute perplexity.\n",
        "    Returns:\n",
        "      A pair (perplexity, prob) where `perplexity` is the perplexity computed\n",
        "      for `filename`. `prob` is the cumulative product of probabilities of all\n",
        "      the bytes in `filename` to verify that this language model is\n",
        "      probabilistic or not. `prob` should be close to 1, otherwise, this is not\n",
        "      a language model.\n",
        "    \"\"\"\n",
        "    # Cumulative log_prob for perplexity computation.\n",
        "    cumulative_log_prob = 0.0\n",
        "    # Verify the distribution so that this language model is probabilistic.\n",
        "    prob = 1.0\n",
        "    # Total number of bytes.\n",
        "    total_bytes = 0\n",
        "    with open(filename, 'br') as f:\n",
        "      for line in f:\n",
        "        state = self.initial_state()\n",
        "        prev_x = self.BOS\n",
        "        for x in line:\n",
        "          log_probs, state = self.logprob(state, prev_x)\n",
        "          assert log_probs.size == 256, f\"expected 256, got: {log_probs.size}\"\n",
        "          cumulative_log_prob += log_probs[x]\n",
        "\n",
        "          probs = np.exp(log_probs)\n",
        "          assert (probs >= 0).all(), \"expected greater than or equal to zero.\"\n",
        "          prob *= np.sum(probs)  # Sum of `probs` should be close to 1.\n",
        "\n",
        "          prev_x = x\n",
        "\n",
        "        total_bytes += len(line)\n",
        "\n",
        "    return np.exp(-cumulative_log_prob / total_bytes), prob"
      ],
      "metadata": {
        "id": "oMcNDJo-0eaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and report perplexity\n",
        "\n",
        "Please run the following code block to report the final perplexity of three language models. You can change the hyperparameters to the language model, e.g., arguments for constructing three models, `model_cs`, `model_de` and `model_zh`. However, do not change the rest of the code for a fair comparison with others.\n",
        "\n",
        "We will rank your \"adjusted\" perplexity results from three language models after adding penalty terms."
      ],
      "metadata": {
        "id": "kSbRCBqpToid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes md5 hash to make sure that the correct datasets are used for training\n",
        "# and testing.\n",
        "!md5sum byte-language-model-2023/*\n",
        "\n",
        "# Train a Czech language model using Czech data. Note that you can modify the\n",
        "# arguments to `ByteLM` to set hyperparameters to the language model.\n",
        "model_cs = ByteLM(\"byte-language-model-2023/news-commentary-v18.cs.txt\")\n",
        "\n",
        "# Train a German language model using German data. Note that you can modify the\n",
        "# arguments to `ByteLM` to set hyperparameters to the language model.\n",
        "model_de = ByteLM(\"byte-language-model-2023/news-commentary-v18.de.txt\")\n",
        "\n",
        "# Train a Chinese language model using Chinese data. Note that you can modify\n",
        "# the arguments to `ByteLM` to set hyperparameters to the language model.\n",
        "model_zh = ByteLM(\"byte-language-model-2023/news-commentary-v18.zh.txt\")\n",
        "\n",
        "# DO NOT CHANGE THE FOLLOWING CODES FOR FAIR COMPARISON.\n",
        "\n",
        "# Testing on Czech data using the language model trained by Czech data.\n",
        "perp_cs, prob_cs = model_cs.perplexity(\"byte-language-model-2023/wmttest2023.cs.txt\")\n",
        "\n",
        "# Testing on German data using the language model trained by German data.\n",
        "perp_de, prob_de = model_de.perplexity(\"byte-language-model-2023/wmttest2023.de.txt\")\n",
        "\n",
        "# Testing on Chinese data using the language model trained by Chinese data.\n",
        "perp_zh, prob_zh = model_zh.perplexity(\"byte-language-model-2023/wmttest2023.zh.txt\")\n",
        "\n",
        "# Computes total perplexity from three languages.\n",
        "perp = perp_cs + perp_de + perp_zh\n",
        "\n",
        "# Computes penalties and simply sums them.\n",
        "penalty_cs = np.maximum(np.abs(1 - prob_cs) - 0.001, 0) * 100\n",
        "penalty_de = np.maximum(np.abs(1 - prob_de) - 0.001, 0) * 100\n",
        "penalty_zh = np.maximum(np.abs(1 - prob_zh) - 0.001, 0) * 100\n",
        "adjusted_perp = perp + penalty_cs + penalty_de + penalty_zh\n",
        "\n",
        "# Print out computation results. \"adjusted perplexity\" is used for ranking.\n",
        "print(f\"cs perplexity: {perp_cs} prob: {prob_cs} penalty: {penalty_cs}\")\n",
        "print(f\"de perplexity: {perp_de} prob: {prob_de} penalty: {penalty_de}\")\n",
        "print(f\"de perplexity: {perp_zh} prob: {prob_zh} penalty: {penalty_zh}\")\n",
        "print(f\"total perplexity: {perp}\")\n",
        "print(f\"adjusted: {adjusted_perp:.4f}\")"
      ],
      "metadata": {
        "id": "nIhSOEdJzqgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef43541-4e37-4ea6-dbb0-fb26f34d920e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27f491a6c461d2476cc1a2636ca335a5  byte-language-model-2023/news-commentary-v18.cs.txt\n",
            "c5cf2b0f973eccb12e45a56039d44f99  byte-language-model-2023/news-commentary-v18.de.txt\n",
            "73393083e83b20fa09d94730ae336ddd  byte-language-model-2023/news-commentary-v18.zh.txt\n",
            "49fac4990f87cbac47cd0811e0b37f34  byte-language-model-2023/wmttest2022.cs.txt\n",
            "4fb8d232846ed6f66662163ff1e319e3  byte-language-model-2023/wmttest2022.de.txt\n",
            "4da911905616d01cce3a06b5354b4146  byte-language-model-2023/wmttest2022.zh.txt\n",
            "dea2aeda559fe2c6237a95a57c48b589  byte-language-model-2023/wmttest2023.cs.txt\n",
            "e9ef45facac4b236d22b2525bf6e3391  byte-language-model-2023/wmttest2023.de.txt\n",
            "d544edaac936c509f958a3f1309124dd  byte-language-model-2023/wmttest2023.zh.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8b90978af385>:59: RuntimeWarning: divide by zero encountered in log\n",
            "  log_probs = np.where(probs == 0.0, -np.inf, np.log(probs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cs perplexity: inf prob: 0.9999999999966394 penalty: 0.0\n",
            "de perplexity: inf prob: 0.9999999999785161 penalty: 0.0\n",
            "de perplexity: inf prob: 0.999999999993634 penalty: 0.0\n",
            "total perplexity: inf\n",
            "adjusted: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add your codes if necessary\n",
        "\n",
        "You can add arbitrary codes here, e.g., running experiments on smaller training data, i.e., `news-commentary-v18-small.cs.txt` and/or `news-commentary-v18-small.de.txt`, together with development data, `byte-language-model-2023/wmttest2022.cs.txt` and/or `byte-language-model-2023/wmttest2022.de.txt`. You can easily add your code by clicking `+ Code` at the top of this notebook, near the menu bar.\n",
        "\n",
        "When you tweak any hyperparameters of your model, you may keep some code run results as a justification of the choices, e.g., run results on the development datasets."
      ],
      "metadata": {
        "id": "Jg8opr-gUVm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can add your code here for your testing purposes, e.g., runs on\n",
        "# development data to tweak your codes in `ByteLM` or find hyperparameters.\n",
        "# However, do not tune on test data."
      ],
      "metadata": {
        "id": "jKTAPE7J6CY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}